concrete <- read.csv('concrete.csv', header=T)
dim(concrete)
colnames(concrete)
head(concrete)
str(concrete)
normalise <- function(x) {
return((x-min(x))/(max(x)-min(x)))
}
concrete_norm <- as.data.frame(lapply(concrete, normalise))
head(concrete_norm)
summary(concrete_norm)
idx <- sample(1:nrow(concrete), 0.75*nrow(concrete))
training <- concrete_norm[idx,]
testing <- concrete_norm[-idx,]
myformula <- strength ~ cement + slag + ash + water + superplastic + coarseagg + fineagg + age
model <- neuralnet(formula=myformula, data=training)
# plot(model)
colnames(testing)
testing_x <- testing[1:8]
model_result <- compute(model, testing_x)
prediction <- model_result$net.result
# 회귀는 수치 값 예상이므로 상관계수로 평가해야 한다.
cor(prediction, testing$strength)
library(neuralnet)
concrete <- read.csv('concrete.csv', header=T)
dim(concrete)
colnames(concrete)
head(concrete)
str(concrete)
normalise <- function(x) {
return((x-min(x))/(max(x)-min(x)))
}
concrete_norm <- as.data.frame(lapply(concrete, normalise))
head(concrete_norm)
summary(concrete_norm)
idx <- sample(1:nrow(concrete), 0.75*nrow(concrete))
training <- concrete_norm[idx,]
testing <- concrete_norm[-idx,]
myformula <- strength ~ cement + slag + ash + water + superplastic + coarseagg + fineagg + age
model <- neuralnet(formula=myformula, data=training)
# plot(model)
colnames(testing)
testing_x <- testing[1:8]
model_result <- compute(model, testing_x)
prediction <- model_result$net.result
# 회귀는 수치 값 예상이므로 상관계수로 평가해야 한다.
cor(prediction, testing$strength)
library(neuralnet)
concrete <- read.csv('concrete.csv', header=T)
dim(concrete)
colnames(concrete)
head(concrete)
str(concrete)
normalise <- function(x) {
return((x-min(x))/(max(x)-min(x)))
}
concrete_norm <- as.data.frame(lapply(concrete, normalise))
head(concrete_norm)
summary(concrete_norm)
idx <- sample(1:nrow(concrete), 0.75*nrow(concrete))
training <- concrete_norm[idx,]
testing <- concrete_norm[-idx,]
myformula <- strength ~ cement + slag + ash + water + superplastic + coarseagg + fineagg + age
model <- neuralnet(formula=myformula, data=training)
# plot(model)
colnames(testing)
testing_x <- testing[1:8]
model_result <- compute(model, testing_x)
prediction <- model_result$net.result
# 회귀는 수치 값 예상이므로 상관계수로 평가해야 한다.
cor(prediction, testing$strength)
library(neuralnet)
concrete <- read.csv('concrete.csv', header=T)
dim(concrete)
colnames(concrete)
head(concrete)
str(concrete)
normalise <- function(x) {
return((x-min(x))/(max(x)-min(x)))
}
concrete_norm <- as.data.frame(lapply(concrete, normalise))
head(concrete_norm)
summary(concrete_norm)
idx <- sample(1:nrow(concrete), 0.75*nrow(concrete))
training <- concrete_norm[idx,]
testing <- concrete_norm[-idx,]
myformula <- strength ~ cement + slag + ash + water + superplastic + coarseagg + fineagg + age
model <- neuralnet(formula=myformula, data=training)
# plot(model)
colnames(testing)
testing_x <- testing[1:8]
model_result <- compute(model, testing_x)
prediction <- model_result$net.result
# 회귀는 수치 값 예상이므로 상관계수로 평가해야 한다.
cor(prediction, testing$strength)
library(neuralnet)
concrete <- read.csv('concrete.csv', header=T)
dim(concrete)
colnames(concrete)
head(concrete)
str(concrete)
normalise <- function(x) {
return((x-min(x))/(max(x)-min(x)))
}
concrete_norm <- as.data.frame(lapply(concrete, normalise))
head(concrete_norm)
summary(concrete_norm)
idx <- sample(1:nrow(concrete), 0.75*nrow(concrete))
training <- concrete_norm[idx,]
testing <- concrete_norm[-idx,]
myformula <- strength ~ cement + slag + ash + water + superplastic + coarseagg + fineagg + age
model <- neuralnet(formula=myformula, data=training)
# plot(model)
colnames(testing)
testing_x <- testing[1:8]
model_result <- compute(model, testing_x)
prediction <- model_result$net.result
# 회귀는 수치 값 예상이므로 상관계수로 평가해야 한다.
cor(prediction, testing$strength)
model <- neuralnet(formula=myformula, data=training, hidden=c(10:3))
# plot(model)
colnames(testing)
testing_x <- testing[1:8]
model_result <- compute(model, testing_x)
prediction <- model_result$net.result
# 회귀는 수치 값 예상이므로 상관계수로 평가해야 한다.
cor(prediction, testing$strength)
model <- neuralnet(formula=myformula, data=training, hidden=c(5:3))
# plot(model)
colnames(testing)
testing_x <- testing[1:8]
model_result <- compute(model, testing_x)
prediction <- model_result$net.result
# 회귀는 수치 값 예상이므로 상관계수로 평가해야 한다.
cor(prediction, testing$strength)
model <- neuralnet(formula=myformula, data=training, hidden=c(5:3))
# plot(model)
colnames(testing)
testing_x <- testing[1:8]
model_result <- compute(model, testing_x)
prediction <- model_result$net.result
# 회귀는 수치 값 예상이므로 상관계수로 평가해야 한다.
cor(prediction, testing$strength)
model <- neuralnet(formula=myformula, data=training, hidden=c(5:2))
# plot(model)
colnames(testing)
testing_x <- testing[1:8]
model_result <- compute(model, testing_x)
prediction <- model_result$net.result
# 회귀는 수치 값 예상이므로 상관계수로 평가해야 한다.
cor(prediction, testing$strength)
model <- neuralnet(formula=myformula, data=training, hidden=c(100:100))
testing_x <- testing[1:8]
model_result <- compute(model, testing_x)
prediction <- model_result$net.result
cor(prediction, testing$strength)
plot(model)
plot(model)
plot(model)
year <- c(2010:2019)
month <- c('01','02','03','04','05','06','07','08','09','10','11','12')
day <- c(month, as.character(c(13:31))
)
day
setwd("D:/GitHub/tjproject/R/crawling")
################################################################################
# Naver News
################################################################################
# Library imports
library(rvest)
# Functions
get_html <- function(url) {
html <- read_html(url)
return(html)
}
# Section - Politics, Economics, Society, Culture, World, Science, Photo, TV
################################################################################
sec_id <- as.character(c(100:105))
year <- c(2010:2019)
month <- c('01','02','03','04','05','06','07','08','09','10','11','12')
day <- c(month, as.character(c(13:31))
# 2019/11/05 Data
url_1 <- 'https://news.naver.com/main/ranking/popularDay.nhn?rankingType=popular_day'
url_2 <- '&sectionId='
url_3 <- '&date='
df <- data.frame()
for(y in year) {
for(m in month) {
for(d in day) {
for(id in sec_id) {
# print(id)
date <- paste(y, m, d, sep='')
url <- paste(url_1, url_2, id, url_3, date, sep='')
html <- get_html(url)
item <- html %>% html_nodes('.ranking_item')
category <- html %>% html_nodes('.is_selected') %>% html_nodes('a') %>% html_text()
category <- category[2]
category <- rep(gsub('선택됨', '', category), 30)
title <- item %>% html_nodes('.ranking_headline') %>% html_nodes('a') %>% html_text()
source <- item %>% html_nodes('.ranking_office') %>% html_text()
view <- item %>% html_nodes('.ranking_view') %>% html_text()
date <- rep(date, 30)
temp_df <- data.frame(category, title, source, view, date)
df <- rbind(df, temp_df)
}
}
}
}
write.csv(df, 'news.csv')
################################################################################
# Naver News
################################################################################
# Library imports
library(rvest)
# Functions
get_html <- function(url) {
html <- read_html(url)
return(html)
}
# Section - Politics, Economics, Society, Culture, World, Science, Photo, TV
################################################################################
sec_id <- as.character(c(100:105))
year <- c(2010:2019)
month <- c('01','02','03','04','05','06','07','08','09','10','11','12')
day <- c(month, as.character(c(13:31)))
# 2019/11/05 Data
url_1 <- 'https://news.naver.com/main/ranking/popularDay.nhn?rankingType=popular_day'
url_2 <- '&sectionId='
url_3 <- '&date='
df <- data.frame()
for(y in year) {
for(m in month) {
for(d in day) {
for(id in sec_id) {
# print(id)
date <- paste(y, m, d, sep='')
url <- paste(url_1, url_2, id, url_3, date, sep='')
html <- get_html(url)
item <- html %>% html_nodes('.ranking_item')
category <- html %>% html_nodes('.is_selected') %>% html_nodes('a') %>% html_text()
category <- category[2]
category <- rep(gsub('선택됨', '', category), 30)
title <- item %>% html_nodes('.ranking_headline') %>% html_nodes('a') %>% html_text()
source <- item %>% html_nodes('.ranking_office') %>% html_text()
view <- item %>% html_nodes('.ranking_view') %>% html_text()
date <- rep(date, 30)
temp_df <- data.frame(category, title, source, view, date)
df <- rbind(df, temp_df)
}
}
}
}
write.csv(df, 'news.csv')
y
d
paste(y, d, sep='')
paste(y, m, d, sep='')
url <- paste(url_1, url_2, id, url_3, date, sep='')
url
id
url
ulr_1
url_1
url_2
url_3
date
date <- paste(y,m,d,sep='')
date
url <- paste(url_1, url_2, id, url_3, date, sep='')
url
html <- get_html(url)
html
item <- html %>% html_nodes('.ranking_item')
category <- html %>% html_nodes('.is_selected') %>% html_nodes('a') %>% html_text()
category <- category[2]
category <- rep(gsub('선택됨', '', category), 30)
title <- item %>% html_nodes('.ranking_headline') %>% html_nodes('a') %>% html_text()
source <- item %>% html_nodes('.ranking_office') %>% html_text()
view <- item %>% html_nodes('.ranking_view') %>% html_text()
date <- rep(date, 30)
temp_df <- data.frame(category, title, source, view, date)
df <- rbind(df, temp_df)
date
length(date)
length(category)
length(title)
length(source)
length view
length(view)
is.na(view)
is.na(view) == T
is.na(view) == TRUE
mode(is.na(view))
if(is.na(view) == T) { print('True')}
################################################################################
# Naver News
################################################################################
# Library imports
library(rvest)
# Functions
get_html <- function(url) {
html <- read_html(url)
return(html)
}
# Section - Politics, Economics, Society, Culture, World, Science, Photo, TV
################################################################################
sec_id <- as.character(c(100:105))
year <- c(2010:2019)
month <- c('01','02','03','04','05','06','07','08','09','10','11','12')
day <- c(month, as.character(c(13:31)))
# 2019/11/05 Data
url_1 <- 'https://news.naver.com/main/ranking/popularDay.nhn?rankingType=popular_day'
url_2 <- '&sectionId='
url_3 <- '&date='
df <- data.frame()
for(y in year) {
for(m in month) {
for(d in day) {
for(id in sec_id) {
# print(id)
date <- paste(y, m, d, sep='')
url <- paste(url_1, url_2, id, url_3, date, sep='')
html <- get_html(url)
item <- html %>% html_nodes('.ranking_item')
category <- html %>% html_nodes('.is_selected') %>% html_nodes('a') %>% html_text()
category <- category[2]
category <- rep(gsub('선택됨', '', category), 30)
title <- item %>% html_nodes('.ranking_headline') %>% html_nodes('a') %>% html_text()
source <- item %>% html_nodes('.ranking_office') %>% html_text()
view <- item %>% html_nodes('.ranking_view') %>% html_text()
if(length(view) == 0) {
view <- rep(NA, 30)
}
date <- rep(date, 30)
temp_df <- data.frame(category, title, source, view, date)
df <- rbind(df, temp_df)
}
}
}
}
write.csv(df, 'news.csv')
dim9df
dim(df)
print(date)
################################################################################
# Naver News
################################################################################
# Library imports
library(rvest)
# Functions
get_html <- function(url) {
html <- read_html(url)
return(html)
}
# Section - Politics, Economics, Society, Culture, World, Science, Photo, TV
################################################################################
sec_id <- as.character(c(100:105))
year <- c(2010:2019)
month <- c('01','02','03','04','05','06','07','08','09','10','11','12')
day <- c(month, as.character(c(13:31)))
# 2019/11/05 Data
url_1 <- 'https://news.naver.com/main/ranking/popularDay.nhn?rankingType=popular_day'
url_2 <- '&sectionId='
url_3 <- '&date='
df <- data.frame()
for(y in year) {
for(m in month) {
for(d in day) {
for(id in sec_id) {
# print(id)
date <- paste(y, m, d, sep='')
print(date)
url <- paste(url_1, url_2, id, url_3, date, sep='')
html <- get_html(url)
item <- html %>% html_nodes('.ranking_item')
category <- html %>% html_nodes('.is_selected') %>% html_nodes('a') %>% html_text()
category <- category[2]
category <- rep(gsub('선택됨', '', category), 30)
title <- item %>% html_nodes('.ranking_headline') %>% html_nodes('a') %>% html_text()
source <- item %>% html_nodes('.ranking_office') %>% html_text()
view <- item %>% html_nodes('.ranking_view') %>% html_text()
if(length(view) == 0) {
view <- rep(NA, 30)
}
date <- rep(date, 30)
temp_df <- data.frame(category, title, source, view, date)
df <- rbind(df, temp_df)
}
}
}
}
write.csv(df, 'news.csv')
################################################################################
# Naver News
################################################################################
# Library imports
library(rvest)
# Functions
get_html <- function(url) {
html <- read_html(url)
return(html)
}
check_cat <- function(vec) {
len <- length(vec)
if(len < 30) {
extra <- rep(NA, len)
return(c(vec, extra))
} else {
return(vec)
}
}
# Section - Politics, Economics, Society, Culture, World, Science, Photo, TV
################################################################################
sec_id <- as.character(c(100:105))
year <- c(2010:2019)
month <- c('01','02','03','04','05','06','07','08','09','10','11','12')
day <- c(month, as.character(c(13:31)))
# 2019/11/05 Data
url_1 <- 'https://news.naver.com/main/ranking/popularDay.nhn?rankingType=popular_day'
url_2 <- '&sectionId='
url_3 <- '&date='
df <- data.frame()
for(y in year) {
for(m in month) {
for(d in day) {
for(id in sec_id) {
# print(id)
date <- paste(y, m, d, sep='')
print(date)
url <- paste(url_1, url_2, id, url_3, date, sep='')
html <- get_html(url)
item <- html %>% html_nodes('.ranking_item')
category <- html %>% html_nodes('.is_selected') %>% html_nodes('a') %>% html_text()
category <- category[2]
category <- rep(gsub('선택됨', '', category), 30)
title <- item %>% html_nodes('.ranking_headline') %>% html_nodes('a') %>% html_text()
source <- item %>% html_nodes('.ranking_office') %>% html_text()
view <- item %>% html_nodes('.ranking_view') %>% html_text()
if(length(view) == 0) {
view <- rep(NA, 30)
}
title <- check_cat(title)
source <- check_cat(source)
view <- check_cat(view)
date <- rep(date, 30)
temp_df <- data.frame(category, title, source, view, date)
df <- rbind(df, temp_df)
}
}
}
}
write.csv(df, 'news.csv')
################################################################################
# Naver News
################################################################################
# Library imports
library(rvest)
# Functions
get_html <- function(url) {
html <- read_html(url)
return(html)
}
check_cat <- function(vec) {
len <- length(vec)
if(len < 30) {
extra <- rep(NA, (30-len))
return(c(vec, extra))
} else {
return(vec)
}
}
# Section - Politics, Economics, Society, Culture, World, Science, Photo, TV
################################################################################
sec_id <- as.character(c(100:105))
year <- c(2010:2019)
month <- c('01','02','03','04','05','06','07','08','09','10','11','12')
day <- c(month, as.character(c(13:31)))
# 2019/11/05 Data
url_1 <- 'https://news.naver.com/main/ranking/popularDay.nhn?rankingType=popular_day'
url_2 <- '&sectionId='
url_3 <- '&date='
df <- data.frame()
for(y in year) {
for(m in month) {
for(d in day) {
for(id in sec_id) {
# print(id)
date <- paste(y, m, d, sep='')
print(date)
url <- paste(url_1, url_2, id, url_3, date, sep='')
html <- get_html(url)
item <- html %>% html_nodes('.ranking_item')
category <- html %>% html_nodes('.is_selected') %>% html_nodes('a') %>% html_text()
category <- category[2]
category <- rep(gsub('선택됨', '', category), 30)
title <- item %>% html_nodes('.ranking_headline') %>% html_nodes('a') %>% html_text()
source <- item %>% html_nodes('.ranking_office') %>% html_text()
view <- item %>% html_nodes('.ranking_view') %>% html_text()
if(length(view) == 0) {
view <- rep(NA, 30)
}
title <- check_cat(title)
source <- check_cat(source)
view <- check_cat(view)
date <- rep(date, 30)
temp_df <- data.frame(category, title, source, view, date)
df <- rbind(df, temp_df)
}
}
}
}
write.csv(df, 'news.csv')
