####################################################################################################
# Crawling
year <- as.character(c(2008:2019))
month <- c('01','02','03','04','05','06','07','08','09','10','11','12')
day <- c(c('01','02','03','04','05','06','07','08','09'), 10:31)
stopDate <- '20191114'
flag = F
for(y in year) {
if(flag == T) {
break
}
df <- data.frame()
print(y)
for(m in month) {
if(flag == T) {
break
}
for(d in day) {
# Disgard months with no 31st (except February)
if(m %in% c('04','06','09','11') & d == 31) {
next
}
# Disgard February (special cases)
if(m %in% c('02') & d >= 30) {
next
}
# Main
Sys.setenv("http_proxy"="")
Sys.setenv("no_proxy"=T)
Sys.setenv("no_proxy"=1)
url <- 'https://news.naver.com/main/ranking/popularDay.nhn?rankingType=popular_day&sectionId=100&date='
date <- paste(y, m, d, sep='')
if(date == stopDate) {
flag = T
break
}
html <- read_html(paste(url, date, sep=''))
list <- html %>% html_nodes('.ranking_list')
title <- list %>% html_nodes('.ranking_headline') %>% html_nodes('a') %>% html_text()
subti <- list %>% html_nodes('.ranking_lede') %>% html_text()
source <- list %>% html_nodes('.ranking_office') %>% html_text()
cmt <- list %>% html_nodes('.count_cmt') %>% html_text()
len <- length(title) # number of articles in this page
if(len == 0) { # If nothing is crawled, skip
next
}
if(length(cmt) == 0) {
cmt <- rep(NA, len)
}
# pre-processing
subti <- clean(subti) # removes whitespace, \t, \r, \n
cmt <- cleanc(cmt) # removes commas
tdf <- data.frame(rank=c(1:len), title=title, subti=subti, source=source, cmt=cmt, date=rep(date, len))
df <- rbind(tdf, df)
}
}
filename <- paste('cmt_', year, '.csv', sep='')
write.csv(df, filename)
}
####################################################################################################
# Naver News Page by Most Comments
# Category : Politics
####################################################################################################
# Library Import
library(rvest)
####################################################################################################
# Functions
clean <- function(x) { # Function to remove new lines, tabs, etc...
library(stringr)
x <- gsub("\t", "", x)
x <- gsub("\r", "", x)
x <- gsub("\n", "", x)
x <- str_trim(x)
return(x)
}
cleanc <- function(x) { # Function to remove commas in comments
x <- gsub(',', '', x)
return(x)
}
####################################################################################################
# Crawling
year <- as.character(c(2008:2019))
month <- c('01','02','03','04','05','06','07','08','09','10','11','12')
day <- c(c('01','02','03','04','05','06','07','08','09'), 10:31)
stopDate <- '20191114'
flag = F
for(y in year) {
if(flag == T) {
break
}
df <- data.frame()
print(y)
for(m in month) {
if(flag == T) {
break
}
for(d in day) {
# Disgard months with no 31st (except February)
if(m %in% c('04','06','09','11') & d == 31) {
next
}
# Disgard February (special cases)
if(m %in% c('02') & d >= 30) {
next
}
# Main
Sys.setenv("http_proxy"="")
Sys.setenv("no_proxy"=T)
Sys.setenv("no_proxy"=1)
url <- 'https://news.naver.com/main/ranking/popularDay.nhn?rankingType=popular_day&sectionId=100&date='
date <- paste(y, m, d, sep='')
if(date == stopDate) {
flag = T
break
}
html <- read_html(paste(url, date, sep=''))
list <- html %>% html_nodes('.ranking_list')
title <- list %>% html_nodes('.ranking_headline') %>% html_nodes('a') %>% html_text()
subti <- list %>% html_nodes('.ranking_lede') %>% html_text()
source <- list %>% html_nodes('.ranking_office') %>% html_text()
cmt <- list %>% html_nodes('.count_cmt') %>% html_text()
len <- length(title) # number of articles in this page
if(len == 0) { # If nothing is crawled, skip
next
}
if(length(cmt) == 0) {
cmt <- rep(NA, len)
}
# pre-processing
subti <- clean(subti) # removes whitespace, \t, \r, \n
cmt <- cleanc(cmt) # removes commas
tdf <- data.frame(rank=c(1:len), title=title, subti=subti, source=source, cmt=cmt, date=rep(date, len))
df <- rbind(tdf, df)
}
}
filename <- paste('cmt_', year, '.csv', sep='')
write.csv(df, filename)
}
filename <- paste('cmt_', y, '.csv', sep='')
####################################################################################################
# Naver News Page by Most Comments
# Category : Politics
####################################################################################################
# Library Import
library(rvest)
####################################################################################################
# Functions
clean <- function(x) { # Function to remove new lines, tabs, etc...
library(stringr)
x <- gsub("\t", "", x)
x <- gsub("\r", "", x)
x <- gsub("\n", "", x)
x <- str_trim(x)
return(x)
}
cleanc <- function(x) { # Function to remove commas in comments
x <- gsub(',', '', x)
return(x)
}
####################################################################################################
# Crawling
year <- as.character(c(2008:2019))
month <- c('01','02','03','04','05','06','07','08','09','10','11','12')
day <- c(c('01','02','03','04','05','06','07','08','09'), 10:31)
stopDate <- '20191114'
flag = F
for(y in year) {
if(flag == T) {
break
}
df <- data.frame()
print(y)
for(m in month) {
if(flag == T) {
break
}
for(d in day) {
# Disgard months with no 31st (except February)
if(m %in% c('04','06','09','11') & d == 31) {
next
}
# Disgard February (special cases)
if(m %in% c('02') & d >= 30) {
next
}
# Main
Sys.setenv("http_proxy"="")
Sys.setenv("no_proxy"=T)
Sys.setenv("no_proxy"=1)
url <- 'https://news.naver.com/main/ranking/popularDay.nhn?rankingType=popular_day&sectionId=100&date='
date <- paste(y, m, d, sep='')
if(date == stopDate) {
flag = T
break
}
html <- read_html(paste(url, date, sep=''))
list <- html %>% html_nodes('.ranking_list')
title <- list %>% html_nodes('.ranking_headline') %>% html_nodes('a') %>% html_text()
subti <- list %>% html_nodes('.ranking_lede') %>% html_text()
source <- list %>% html_nodes('.ranking_office') %>% html_text()
cmt <- list %>% html_nodes('.count_cmt') %>% html_text()
len <- length(title) # number of articles in this page
if(len == 0) { # If nothing is crawled, skip
next
}
if(length(cmt) == 0) {
cmt <- rep(NA, len)
}
# pre-processing
subti <- clean(subti) # removes whitespace, \t, \r, \n
cmt <- cleanc(cmt) # removes commas
tdf <- data.frame(rank=c(1:len), title=title, subti=subti, source=source, cmt=cmt, date=rep(date, len))
df <- rbind(tdf, df)
}
}
filename <- paste('cmt_', y, '.csv', sep='')
write.csv(df, filename)
}
####################################################################################################
# Naver News Page by Most Comments
# Category : Politics
####################################################################################################
# Library Import
library(rvest)
####################################################################################################
# Functions
clean <- function(x) { # Function to remove new lines, tabs, etc...
library(stringr)
x <- gsub("\t", "", x)
x <- gsub("\r", "", x)
x <- gsub("\n", "", x)
x <- str_trim(x)
return(x)
}
cleanc <- function(x) { # Function to remove commas in comments
x <- gsub(',', '', x)
return(x)
}
####################################################################################################
# Crawling
year <- as.character(c(2008:2019))
month <- c('01','02','03','04','05','06','07','08','09','10','11','12')
day <- c(c('01','02','03','04','05','06','07','08','09'), 10:31)
stopDate <- '20191114'
flag = F
for(y in year) {
if(flag == T) {
break
}
df <- data.frame()
for(m in month) {
if(flag == T) {
break
}
for(d in day) {
# Disgard months with no 31st (except February)
if(m %in% c('04','06','09','11') & d == 31) {
next
}
# Disgard February (special cases)
if(m %in% c('02') & d >= 30) {
next
}
# Main
Sys.setenv("http_proxy"="")
Sys.setenv("no_proxy"=T)
Sys.setenv("no_proxy"=1)
url <- 'https://news.naver.com/main/ranking/popularDay.nhn?rankingType=popular_day&sectionId=100&date='
date <- paste(y, m, d, sep='')
if(date == stopDate) {
flag = T
break
}
print(date)
html <- read_html(paste(url, date, sep=''))
list <- html %>% html_nodes('.ranking_list')
title <- list %>% html_nodes('.ranking_headline') %>% html_nodes('a') %>% html_text()
subti <- list %>% html_nodes('.ranking_lede') %>% html_text()
source <- list %>% html_nodes('.ranking_office') %>% html_text()
cmt <- list %>% html_nodes('.count_cmt') %>% html_text()
len <- length(title) # number of articles in this page
if(len == 0) { # If nothing is crawled, skip
next
}
if(length(cmt) == 0) {
cmt <- rep(NA, len)
}
# pre-processing
subti <- clean(subti) # removes whitespace, \t, \r, \n
cmt <- cleanc(cmt) # removes commas
tdf <- data.frame(rank=c(1:len), title=title, subti=subti, source=source, cmt=cmt, date=rep(date, len))
df <- rbind(tdf, df)
}
}
filename <- paste('cmt_', y, '.csv', sep='')
write.csv(df, filename)
}
####################################################################################################
# Naver News Page by Most Comments
# Category : Politics
####################################################################################################
# Library Import
library(rvest)
####################################################################################################
# Functions
clean <- function(x) { # Function to remove new lines, tabs, etc...
library(stringr)
x <- gsub("\t", "", x)
x <- gsub("\r", "", x)
x <- gsub("\n", "", x)
x <- str_trim(x)
return(x)
}
cleanc <- function(x) { # Function to remove commas in comments
x <- gsub(',', '', x)
return(x)
}
####################################################################################################
# Crawling
year <- as.character(c(2012:2019))
month <- c('01','02','03','04','05','06','07','08','09','10','11','12')
day <- c(c('01','02','03','04','05','06','07','08','09'), 10:31)
stopDate <- '20191114'
flag = F
for(y in year) {
if(flag == T) {
break
}
df <- data.frame()
for(m in month) {
if(flag == T) {
break
}
for(d in day) {
# Disgard months with no 31st (except February)
if(m %in% c('04','06','09','11') & d == 31) {
next
}
# Disgard February (special cases)
if(m %in% c('02') & d >= 30) {
next
}
# Main
Sys.setenv("http_proxy"="")
Sys.setenv("no_proxy"=T)
Sys.setenv("no_proxy"=1)
url <- 'https://news.naver.com/main/ranking/popularDay.nhn?rankingType=popular_day&sectionId=100&date='
date <- paste(y, m, d, sep='')
if(date == stopDate) {
flag = T
break
}
print(date)
html <- read_html(paste(url, date, sep=''))
list <- html %>% html_nodes('.ranking_list')
title <- list %>% html_nodes('.ranking_headline') %>% html_nodes('a') %>% html_text()
subti <- list %>% html_nodes('.ranking_lede') %>% html_text()
source <- list %>% html_nodes('.ranking_office') %>% html_text()
cmt <- list %>% html_nodes('.count_cmt') %>% html_text()
len <- length(title) # number of articles in this page
if(len == 0) { # If nothing is crawled, skip
next
}
if(length(cmt) == 0) {
cmt <- rep(NA, len)
}
# pre-processing
subti <- clean(subti) # removes whitespace, \t, \r, \n
cmt <- cleanc(cmt) # removes commas
tdf <- data.frame(rank=c(1:len), title=title, subti=subti, source=source, cmt=cmt, date=rep(date, len))
df <- rbind(tdf, df)
}
}
filename <- paste('cmt_', y, '.csv', sep='')
write.csv(df, filename)
}
####################################################################################################
# Naver News Page by Most Comments
# Category : Politics
####################################################################################################
# Library Import
library(rvest)
####################################################################################################
# Functions
clean <- function(x) { # Function to remove new lines, tabs, etc...
library(stringr)
x <- gsub("\t", "", x)
x <- gsub("\r", "", x)
x <- gsub("\n", "", x)
x <- str_trim(x)
return(x)
}
cleanc <- function(x) { # Function to remove commas in comments
x <- gsub(',', '', x)
return(x)
}
####################################################################################################
# Crawling
year <- as.character(c(2013:2019))
month <- c('01','02','03','04','05','06','07','08','09','10','11','12')
day <- c(c('01','02','03','04','05','06','07','08','09'), 10:31)
stopDate <- '20191114'
flag = F
for(y in year) {
if(flag == T) {
break
}
df <- data.frame()
for(m in month) {
if(flag == T) {
break
}
for(d in day) {
# Disgard months with no 31st (except February)
if(m %in% c('04','06','09','11') & d == 31) {
next
}
# Disgard February (special cases)
if(m %in% c('02') & d >= 30) {
next
}
# Main
Sys.setenv("http_proxy"="")
Sys.setenv("no_proxy"=T)
Sys.setenv("no_proxy"=1)
url <- 'https://news.naver.com/main/ranking/popularDay.nhn?rankingType=popular_day&sectionId=100&date='
date <- paste(y, m, d, sep='')
if(date == stopDate) {
flag = T
break
}
print(date)
html <- read_html(paste(url, date, sep=''))
list <- html %>% html_nodes('.ranking_list')
title <- list %>% html_nodes('.ranking_headline') %>% html_nodes('a') %>% html_text()
subti <- list %>% html_nodes('.ranking_lede') %>% html_text()
source <- list %>% html_nodes('.ranking_office') %>% html_text()
cmt <- list %>% html_nodes('.count_cmt') %>% html_text()
len <- length(title) # number of articles in this page
if(len == 0) { # If nothing is crawled, skip
next
}
if(length(cmt) == 0) {
cmt <- rep(NA, len)
}
# pre-processing
subti <- clean(subti) # removes whitespace, \t, \r, \n
cmt <- cleanc(cmt) # removes commas
tdf <- data.frame(rank=c(1:len), title=title, subti=subti, source=source, cmt=cmt, date=rep(date, len))
df <- rbind(tdf, df)
}
}
filename <- paste('cmt_', y, '.csv', sep='')
write.csv(df, filename)
}
setwd("D:/GitHub/tjproject/R/resources")
################################################################################
# view count analysis
################################################################################
df <- data.frame()
data <- read.csv(filename, stringsAsFactors=F)
filename <- paste('view_', year, '.csv', sep='')
data <- read.csv(view_2018, stringsAsFactors=F)
data <- read.csv('view_2018.csv', stringsAsFactors=F)
colnames(data)
################################################################################
# view count analysis
################################################################################
df <- data.frame()
for(year in c(2007:2019)) {
filename <- paste('view_', year, '.csv', sep='')
data <- read.csv(filename, stringsAsFactors=F)
data <- data[,c(2, 5, 6, 7)]
df <- rbind(df, data)
}
dim(df)
colnames(df)
head(df)
table(df$source, df$view)
table(unique(df$source), df$view)
table(df$source, df$rank)
length(unique(df$source))
library(dplyr)
top10 <- df %>% subset(rank <= 10) %>% sort(decreasing=T)
colnames(df)
top10 <- df %>% subset('rank' <= 10) %>% sort(decreasing=T)
table(top10$source, top10$rank)
top10
top10 <- df %>% subset('rank' <= 10) %>% sort(decreasing=T)
top10 <- df %>% subset(rank <= 10) %>% sort(decreasing=T)
top10 <- df %>% subset(rank <= 10) %>% sort(rank, decreasing=T)
top10 <- df %>% subset(rank <= 10) %>% sort('rank', decreasing=T)
top10 <- df %>% subset(rank <= 10)
table(top10$source, top10$rank)
?sort
top10 <- df %>% subset(rank <= 10)
top10 <- as.data.frame(table(top10$source, top10$rank))
top10
table(top10$source, top10$rank)
table(top10$source, top10$rank)
table(top10$source, top10$rank)
table(top10$source, top10$rank)
table(top10$source, top10$rank)
table(top10$source, top10$rank)
table(top10$source, top10$rank)
top10 <- df %>% subset(rank = 10)
head(top10)
top10 <- df %>% subset(rank == 10)
head(top10)
top10 <- df %>% subset(rank == 1)
head(top10)
top <- df %>% subset(rank == 1)
