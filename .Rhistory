#     0.9780036 11.8011635
# sample estimates:
#     ratio of variances
# 3.39729
# p-value(0.054) > 0.05 이므로 귀무 가설 채택.
# '경제'와 '세계'간의 분포 형태가 동질하다고 볼 수 있다.
dbDisconnectAll()
chisq.test(matrix(c(LmViewTotal, WmViewTotal), byrow = T, ncol = 12))
chisq.test(matrix(c(LmViewTotal/10000, WmViewTotal/10000), byrow = T, ncol = 12))
chisq.test(matrix(c(LmViewTotal/100000, WmViewTotal/100000), byrow = T, ncol = 12))
chisq.test(matrix(c(LmViewTotal/1000000, WmViewTotal/1000000), byrow = T, ncol = 12))
chisq.test(matrix(c(LmViewTotal/10000000, WmViewTotal/10000000), byrow = T, ncol = 12))
chisq.test(matrix(c(LmViewTotal/1000000, WmViewTotal/1000000), byrow = T, ncol = 12))
tmp_mx <- matrix(c(EmCmtTotal/1000000, LmCmtTotal/1000000), byrow = T, ncol = 12)
chisq.test(tmp_mx)
####################################################################################################
# Library
library(stringr)
library(reshape2)
library(ggplot2)
source("base/db.R")
####################################################################################################
# Variable
sections <- c("econ", "IT", "life_cult", "politics", "soc", "world")
####################################################################################################
# Function
dbDisconnectAll <- function(){
ile <- length(dbListConnections(MySQL())  )
lapply( dbListConnections(MySQL()), function(x) dbDisconnect(x) )
cat(sprintf("%s connection(s) closed.\n", ile))
}
## param : section and type(Comment or View)
getSectionData <- function(section, type) {
query01 <- paste('select * from news_',section,' where newsid like "%',type,'%"', sep = '')
dfOne <- dbGetQuery(conn, query01)
return(dfOne)
}
getMonthlyCmt <- function(df) {
len <- nrow(df)
# cat("len:", len, "\n")
x1 <- c(); x2 <- c(); x3 <- c(); x4 <- c(); x5 <- c(); x6 <- c();
x7 <- c(); x8 <- c(); x9 <- c(); x10 <- c(); x11 <- c(); x12 <- c();
# get NCOMMENT(6th col)
for(l in c(1:len)) {
month <- df[l,6] %>% str_sub(6, 7)
# cat(month, "\n")
if(month == "01") { x1 <- c(x1, df[l,8]) }
if(month == "02") { x2 <- c(x2, df[l,8]) }
if(month == "03") { x3 <- c(x3, df[l,8]) }
if(month == "04") { x4 <- c(x4, df[l,8]) }
if(month == "05") { x5 <- c(x5, df[l,8]) }
if(month == "06") { x6 <- c(x6, df[l,8]) }
if(month == "07") { x7 <- c(x7, df[l,8]) }
if(month == "08") { x8 <- c(x8, df[l,8]) }
if(month == "09") { x9 <- c(x9, df[l,8]) }
if(month == "10") { x10 <- c(x10, df[l,8]) }
if(month == "11") { x11 <- c(x11, df[l,8]) }
if(month == "12") { x12 <- c(x12, df[l,8]) }
}
x1 <- sum(as.numeric(x1)); x2 <- sum(as.numeric(x2)); x3 <- sum(as.numeric(x3))
x4 <- sum(as.numeric(x4)); x5 <- sum(as.numeric(x5)); x6 <- sum(as.numeric(x6))
x7 <- sum(as.numeric(x7)); x8 <- sum(as.numeric(x8)); x9 <- sum(as.numeric(x9))
x10 <- sum(as.numeric(x10)); x11 <- sum(as.numeric(x11)); x12 <- sum(as.numeric(x12))
mCmtTotal <- c(x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12)
return(mCmtTotal)
}
####################################################################################################
# Main
type <- 'C'
Edf <- getSectionData(sections[1], type)
Idf <- getSectionData(sections[2], type)
Ldf <- getSectionData(sections[3], type)
Pdf <- getSectionData(sections[4], type)
Sdf <- getSectionData(sections[5], type)
Wdf <- getSectionData(sections[6], type)
# Get Montly Total Comments of each section
EmCmtTotal <- getMonthlyCmt(Edf)
ImCmtTotal <- getMonthlyCmt(Idf)
LmCmtTotal <- getMonthlyCmt(Ldf)
PmCmtTotal <- getMonthlyCmt(Pdf)
SmCmtTotal <- getMonthlyCmt(Sdf)
WmCmtTotal <- getMonthlyCmt(Wdf)
# Combining above vectors into one data frame
CmtTotaldf <- data.frame(
Economy=EmCmtTotal,
IT=ImCmtTotal,
Life_Cult=LmCmtTotal,
Politics=PmCmtTotal,
Society=SmCmtTotal,
World=WmCmtTotal
)
CmtTotaldf$Month <- c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec")
#     Economy     IT Life_Cult Politics Society  World Month
# Jan  659886 112092    260844  1911107 1506685 305898   Jan
# Feb  515121 148336    194695  1717366 1365131 255383   Feb
# Mar  573704 118948    288874  2218102 1709256 354731   Mar
# Apr  407151 108718    154541  1939494 1088885 206754   Apr
# May  496035  96606    178784  2021505 1113531 271456   May
# Jun  414582  94331    209414  1496470 1026012 262090   Jun
# Jul  774258 110048    286352  1857602 1143347 541489   Jul
# Aug  613186 146976    331226  2443301 1590230 582676   Aug
# Sep  394022 129072    254382  2972514 1950946 337660   Sep
# Oct  436861 126394    277971  2222571 1861683 310950   Oct
# Nov  678359 146599    254832  1785598 1618079 270679   Nov
# Dec  700864 127796    206871  1959943 1463843 300111   Dec
CmtPlotData1 <- melt(CmtTotaldf, id.vars="Month")
#    Month  variable   value
# 1    Jan   Economy  659886
# 2    Feb   Economy  515121
# 3    Mar   Economy  573704
# 4    Apr   Economy  407151
# 5    May   Economy  496035
# 6    Jun   Economy  414582
# 7    Jul   Economy  774258
# 8    Aug   Economy  613186
# 9    Sep   Economy  394022
# 10   Oct   Economy  436861
# 11   Nov   Economy  678359
# 12   Dec   Economy  700864
# 13   Jan        IT  112092
# ..........................
# Order the x variable into the order we want.
xorder <- c("Nov","Dec","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct")
CmtPlotData1$Month <- factor(CmtPlotData1$Month, levels=xorder, labels=xorder)
# Plotting the graph
options("scipen" = 100)
CmtPlot1 <- ggplot(CmtPlotData1, aes(Month, value, col=variable)) +
geom_point() +
geom_line(aes(color=variable, group=variable)) +
labs(title="Total Number of Comments per Month (2018.11 ~ 2019.10)")
CmtPlot1
# 귀무 가설 : '정치'와 'IT' 댓글 수의 의존관계는 서로 없다.
chisq.test(tmp_mx)
tmp_mx <- matrix(c(EmCmtTotal/1000000, LmCmtTotal/1000000), byrow = T, ncol = 12)
chisq.test(tmp_mx)
PmCmtTotal
ImCmtTotal
WmCmtTotal
SmCmtTotal
# 귀무 가설 : '정치'와 '사회'간의 분포의 모양이 동질적이다.
fisher.test(x=ImCmtTotal, y=SmCmtTotal)
fisher.test(x=EmCmtTotal, y=WmCmtTotal)
tmp_mx <- matrix(c(EmCmtTotal/100000, LmCmtTotal/100000), byrow = T, ncol = 12)
chisq.test(tmp_mx)
tmp_mx <- matrix(c(EmCmtTotal/10000, LmCmtTotal/10000), byrow = T, ncol = 12)
chisq.test(tmp_mx)
tmp_mx <- matrix(c(ImCmtTotal/10000, LmCmtTotal/10000), byrow = T, ncol = 12)
chisq.test(tmp_mx)
dbDisconnectAll()
####################################################################################################
# Naver News Page by Most Comments
# Category : Politics
####################################################################################################
# Library Import
library(RSelenium)
library(rvest)
library(xlsx)
library(stringr)
####################################################################################################
# Functions
clean <- function(x) { # Function to remove new lines, tabs, etc...
x <- gsub("\t", "", x)
x <- gsub("\r", "", x)
x <- gsub("\n", "", x)
x <- str_trim(x)
return(x)
}
cleanc <- function(x) { # Function to remove commas in comments
x <- gsub(',', '', x)
return(x)
}
chkURL <- function(url) {
out <- tryCatch(
{
html <- read_html(url)
return(html)
},
error=function(cond) {
return(F)
},
warning=function(cond) {
return(F)
},
finally={
cat('chkURL function called\n')
}
)
}
chkElem <- function(elem) {
out <- tryCatch(
{
return(remDr$findElement(elem))
},
error=function(cond) {
return(F)
}
)
}
####################################################################################################
# Crawling
remDr <- remoteDriver(remoteServerAdd='localhost', port=4445L, browserName='chrome')
remDr$open()
year <- as.character(c(2018:2019))
month <- c('01','02','03','04','05','06','07','08','09','10','11','12')
month_eng <- c('Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec')
day <- c(c('01','02','03','04','05','06','07','08','09'), 10:31)
sleepT <- 1/4
startDate <- '20191101'
stopDate <-  '20191130'
startFlag = F
finFlag = F
for(y in year) {
if(finFlag == T) { break }
if(as.integer(y) < as.integer(str_sub(startDate, 1, 4)) & isFALSE(startFlag)) { next }
mcnt <- 0 # Index to iterate month_eng vector
for(m in month) {
mcnt <- mcnt + 1 # Incrementing index
if(finFlag == T) { break }
if(as.integer(m) < as.integer(str_sub(startDate, 5, 6)) & isFALSE(startFlag)) { next }
df <- data.frame(rank=c(), title=c(), subti=c(), source=c(), cmt=c(), date=c())
for(d in day) {
if(finFlag == T) { break }
if(as.integer(d) < as.integer(str_sub(startDate, 7, 8)) & isFALSE(startFlag)) { next }
# Disgard months with no 31st (except February)
if(m %in% c('04','06','09','11') & d == 31) { next }
# Disgard February (special cases)
if(m %in% c('02') & d >= 30) { next }
if(isFALSE(startFlag)) { startFlag = T }
# News Information Crawling
Sys.setenv("http_proxy"="")     # These codes are
Sys.setenv("no_proxy"=T)        # To fix some
Sys.setenv("no_proxy"=1)        # Proxy problems
url <- 'https://news.naver.com/main/ranking/popularMemo.nhn?rankingType=popular_memo&sectionId=100&date='
dat <- paste(y, m, d, sep='')
print(dat)
if(dat == stopDate) { finFlag = T }
url <- paste(url, dat, sep='')
html <- chkURL(url)
# Checks URL
while(is.list(html) == F) { html <- chkURL(url) }
list <- html %>% html_nodes('.ranking_list') %>% html_nodes('.ranking_text')
title <- list %>% html_nodes('.ranking_headline') %>% html_nodes('a') %>% html_text()
subti <- list %>% html_nodes('.ranking_lede') %>% html_text()
source <- list %>% html_nodes('.ranking_office') %>% html_text()
cmt <- list %>% html_nodes('.count_cmt') %>% html_text()
len <- length(title) # number of articles in this page
if(len == 0) { next } # If nothing is crawled, skip
if(length(cmt) == 0) { cmt <- rep(NA, len) }
# Selenium crawling
urls <- list %>% html_nodes('.count_cmt') %>% html_attr('href')
iter <- c(1:length(title))
currCmt <- c(); deleted <- c(); brokenPolicy <- c(); maleRatio <- c(); femaleRatio <- c();
X10 <- c(); X20 <- c(); X30 <- c(); X40 <- c(); X50 <- c(); X60 <- c();
for(i in iter) {
cat('-----', i, '-----\n')
url <- 'https://news.naver.com'
url <- paste(url, urls[i], sep='')
remDr$navigate(url) # navigate to the corresponding news article
Sys.sleep(sleepT)
elm <- remDr$findElements('class','u_cbox_info_txt')
cnt <- 1
while(length(elm) == 0) {
remDr$navigate(url)
Sys.sleep(sleepT * 2^cnt)
elm <- remDr$findElements('class','u_cbox_info_txt')
cat(sleepT * 2^cnt, '\n')
cnt <- cnt + 1
}
currCmt <- c(currCmt, cleanc(as.character(elm[[1]]$getElementText())))
if(is.na(as.integer(currCmt[i]))) { # If current comment is not crawled, change to NA
currCmt[i] = NA
deleted <- c(deleted, NA)
brokenPolicy <- c(brokenPolicy, NA)
maleRatio <- c(maleRatio, NA)
femaleRatio <- c(femaleRatio, NA)
X10 <- c(X10, NA)
X20 <- c(X20, NA)
X30 <- c(X30, NA)
X40 <- c(X40, NA)
X50 <- c(X50, NA)
X60 <- c(X60, NA)
print("No Data - appended NA values")
next()
}
deleted <- c(deleted, as.character(elm[[2]]$getElementText()))
brokenPolicy <- c(brokenPolicy, as.character(elm[[3]]$getElementText()))
if(as.integer(currCmt[i]) < 100) { # If current comment count is less than 100, append NA values to the rest
maleRatio <- c(maleRatio, NA)
femaleRatio <- c(femaleRatio, NA)
X10 <- c(X10, NA)
X20 <- c(X20, NA)
X30 <- c(X30, NA)
X40 <- c(X40, NA)
X50 <- c(X50, NA)
X60 <- c(X60, NA)
print("No Data - appended NA values")
next()
}
elm <- remDr$findElements('class','u_cbox_chart_per')
cnt <- 1
while(length(elm) == 0) {
remDr$navigate(url)
Sys.sleep(sleepT * 2^cnt)
elm <- remDr$findElements('class','u_cbox_chart_per')
cat(sleepT * 2^cnt, '\n')
cnt <- cnt + 1
}
maleRatio <- c(maleRatio, as.character(elm[[1]]$getElementText()))
femaleRatio <- c(femaleRatio, as.character(elm[[2]]$getElementText()))
X10 <- c(X10, as.character(elm[[3]]$getElementText()))
X20 <- c(X20, as.character(elm[[4]]$getElementText()))
X30 <- c(X30, as.character(elm[[5]]$getElementText()))
X40 <- c(X40, as.character(elm[[6]]$getElementText()))
X50 <- c(X50, as.character(elm[[7]]$getElementText()))
X60 <- c(X60, as.character(elm[[8]]$getElementText()))
}
infoDF <- data.frame(currCmt=currCmt, deleted=deleted, brokenPolicy=brokenPolicy, maleRatio=maleRatio, femaleRatio=femaleRatio, X10=X10, X20=X20, X30=X30, X40=X40, X50=X50, X60=X60)
# pre-processing
subti <- clean(subti) # removes whitespace, \t, \r, \n
cmt <- cleanc(cmt); cmt <- clean(cmt) # removes commas
tdf <- data.frame(rank=c(1:len), title=title, subti=subti, source=source, cmt=cmt, date=rep(dat, len))
tdf <- cbind(tdf, infoDF)
df <- rbind(df, tdf)
}
sheName <- paste(month_eng[mcnt], sep='')
file <- paste('D:/GitHub/tjproject/resources/', y, '_comment_data_politics.xlsx', sep='')
write.xlsx(df, file, sheetName=sheName, col.names=T, row.names=F, append=T, password=NULL, showNA=T)
}
}
####################################################################################################
# Naver News Page by Most Comments
# Category : Politics
####################################################################################################
# Library Import
library(RSelenium)
library(rvest)
library(xlsx)
library(stringr)
####################################################################################################
# Functions
clean <- function(x) { # Function to remove new lines, tabs, etc...
x <- gsub("\t", "", x)
x <- gsub("\r", "", x)
x <- gsub("\n", "", x)
x <- str_trim(x)
return(x)
}
cleanc <- function(x) { # Function to remove commas in comments
x <- gsub(',', '', x)
return(x)
}
chkURL <- function(url) {
out <- tryCatch(
{
html <- read_html(url)
return(html)
},
error=function(cond) {
return(F)
},
warning=function(cond) {
return(F)
},
finally={
cat('chkURL function called\n')
}
)
}
chkElem <- function(elem) {
out <- tryCatch(
{
return(remDr$findElement(elem))
},
error=function(cond) {
return(F)
}
)
}
####################################################################################################
# Crawling
remDr <- remoteDriver(remoteServerAdd='localhost', port=4445L, browserName='chrome')
remDr$open()
year <- as.character(c(2018:2019))
month <- c('01','02','03','04','05','06','07','08','09','10','11','12')
month_eng <- c('Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec')
day <- c(c('01','02','03','04','05','06','07','08','09'), 10:31)
sleepT <- 1/4
startDate <- '20191101'
stopDate <-  '20191130'
startFlag = F
finFlag = F
for(y in year) {
if(finFlag == T) { break }
if(as.integer(y) < as.integer(str_sub(startDate, 1, 4)) & isFALSE(startFlag)) { next }
mcnt <- 0 # Index to iterate month_eng vector
for(m in month) {
mcnt <- mcnt + 1 # Incrementing index
if(finFlag == T) { break }
if(as.integer(m) < as.integer(str_sub(startDate, 5, 6)) & isFALSE(startFlag)) { next }
df <- data.frame(rank=c(), title=c(), subti=c(), source=c(), cmt=c(), date=c())
for(d in day) {
if(finFlag == T) { break }
if(as.integer(d) < as.integer(str_sub(startDate, 7, 8)) & isFALSE(startFlag)) { next }
# Disgard months with no 31st (except February)
if(m %in% c('04','06','09','11') & d == 31) { next }
# Disgard February (special cases)
if(m %in% c('02') & d >= 30) { next }
if(isFALSE(startFlag)) { startFlag = T }
# News Information Crawling
Sys.setenv("http_proxy"="")     # These codes are
Sys.setenv("no_proxy"=T)        # To fix some
Sys.setenv("no_proxy"=1)        # Proxy problems
url <- 'https://news.naver.com/main/ranking/popularMemo.nhn?rankingType=popular_memo&sectionId=102&date='
dat <- paste(y, m, d, sep='')
print(dat)
if(dat == stopDate) { finFlag = T }
url <- paste(url, dat, sep='')
html <- chkURL(url)
# Checks URL
while(is.list(html) == F) { html <- chkURL(url) }
list <- html %>% html_nodes('.ranking_list') %>% html_nodes('.ranking_text')
title <- list %>% html_nodes('.ranking_headline') %>% html_nodes('a') %>% html_text()
subti <- list %>% html_nodes('.ranking_lede') %>% html_text()
source <- list %>% html_nodes('.ranking_office') %>% html_text()
cmt <- list %>% html_nodes('.count_cmt') %>% html_text()
len <- length(title) # number of articles in this page
if(len == 0) { next } # If nothing is crawled, skip
if(length(cmt) == 0) { cmt <- rep(NA, len) }
# Selenium crawling
urls <- list %>% html_nodes('.count_cmt') %>% html_attr('href')
iter <- c(1:length(title))
currCmt <- c(); deleted <- c(); brokenPolicy <- c(); maleRatio <- c(); femaleRatio <- c();
X10 <- c(); X20 <- c(); X30 <- c(); X40 <- c(); X50 <- c(); X60 <- c();
for(i in iter) {
cat('-----', i, '-----\n')
url <- 'https://news.naver.com'
url <- paste(url, urls[i], sep='')
remDr$navigate(url) # navigate to the corresponding news article
Sys.sleep(sleepT)
elm <- remDr$findElements('class','u_cbox_info_txt')
cnt <- 1
while(length(elm) == 0) {
remDr$navigate(url)
Sys.sleep(sleepT * 2^cnt)
elm <- remDr$findElements('class','u_cbox_info_txt')
cat(sleepT * 2^cnt, '\n')
cnt <- cnt + 1
}
currCmt <- c(currCmt, cleanc(as.character(elm[[1]]$getElementText())))
if(is.na(as.integer(currCmt[i]))) { # If current comment is not crawled, change to NA
currCmt[i] = NA
deleted <- c(deleted, NA)
brokenPolicy <- c(brokenPolicy, NA)
maleRatio <- c(maleRatio, NA)
femaleRatio <- c(femaleRatio, NA)
X10 <- c(X10, NA)
X20 <- c(X20, NA)
X30 <- c(X30, NA)
X40 <- c(X40, NA)
X50 <- c(X50, NA)
X60 <- c(X60, NA)
print("No Data - appended NA values")
next()
}
deleted <- c(deleted, as.character(elm[[2]]$getElementText()))
brokenPolicy <- c(brokenPolicy, as.character(elm[[3]]$getElementText()))
if(as.integer(currCmt[i]) < 100) { # If current comment count is less than 100, append NA values to the rest
maleRatio <- c(maleRatio, NA)
femaleRatio <- c(femaleRatio, NA)
X10 <- c(X10, NA)
X20 <- c(X20, NA)
X30 <- c(X30, NA)
X40 <- c(X40, NA)
X50 <- c(X50, NA)
X60 <- c(X60, NA)
print("No Data - appended NA values")
next()
}
elm <- remDr$findElements('class','u_cbox_chart_per')
cnt <- 1
while(length(elm) == 0) {
remDr$navigate(url)
Sys.sleep(sleepT * 2^cnt)
elm <- remDr$findElements('class','u_cbox_chart_per')
cat(sleepT * 2^cnt, '\n')
cnt <- cnt + 1
}
maleRatio <- c(maleRatio, as.character(elm[[1]]$getElementText()))
femaleRatio <- c(femaleRatio, as.character(elm[[2]]$getElementText()))
X10 <- c(X10, as.character(elm[[3]]$getElementText()))
X20 <- c(X20, as.character(elm[[4]]$getElementText()))
X30 <- c(X30, as.character(elm[[5]]$getElementText()))
X40 <- c(X40, as.character(elm[[6]]$getElementText()))
X50 <- c(X50, as.character(elm[[7]]$getElementText()))
X60 <- c(X60, as.character(elm[[8]]$getElementText()))
}
infoDF <- data.frame(currCmt=currCmt, deleted=deleted, brokenPolicy=brokenPolicy, maleRatio=maleRatio, femaleRatio=femaleRatio, X10=X10, X20=X20, X30=X30, X40=X40, X50=X50, X60=X60)
# pre-processing
subti <- clean(subti) # removes whitespace, \t, \r, \n
cmt <- cleanc(cmt); cmt <- clean(cmt) # removes commas
tdf <- data.frame(rank=c(1:len), title=title, subti=subti, source=source, cmt=cmt, date=rep(dat, len))
tdf <- cbind(tdf, infoDF)
df <- rbind(df, tdf)
}
sheName <- paste(month_eng[mcnt], sep='')
file <- paste('D:/GitHub/tjproject/resources/', y, '_comment_data_soc.xlsx', sep='')
write.xlsx(df, file, sheetName=sheName, col.names=T, row.names=F, append=T, password=NULL, showNA=T)
}
}
"S123" %in% "S"
"S" %in% "S123"
"S" %in% "SLDKFJL"
